# Code_Idea

**Generated**: 2025-12-30T01:07:24.704442
**Novelty Score**: 0.39
**Source File**: /home/josh/str/projects/codedreamer/codedreamer/proactive.py

---

 ## Analysis

### 1. Current State Assessment
- **What is this code doing?**
  - The `ProactiveContext` class is designed to assemble a context package proactively for use in generating prompts for an LLM (Language Model). It includes various attributes such as `source_file`, `related_files`, `imported_modules`, `graph_context`, and `trm_context`. The `to_prompt_section` method formats these attributes into a structured string that can be used as part of a prompt.
- **What patterns/paradigms is it using?**
  - The class uses dataclass fields to initialize its attributes with default values. It also follows a builder pattern where the `to_prompt_section` method constructs a formatted string by conditionally appending relevant sections based on the presence of specific attributes.

### 2. Identified Issues
- **Dataclass Initialization**:
  - **Line**: `source_file: str`
  - **Issue**: The `source_file` attribute is not initialized with a default value, which can lead to issues if it is accessed before being set.
  - **Why**: This can cause `AttributeError` or other runtime errors if the attribute is accessed without being properly set.

- **List Slicing**:
  - **Lines**: 
    ```python
    sections.append(
        f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
    )
    ```
    ```python
    sections.append(
        f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
    )
    ```
  - **Issue**: The list slicing operations `[:10]` and `[:5]` can be inefficient if the lists are very large.
  - **Why**: Slicing a large list creates a new list, which can consume unnecessary memory and CPU cycles.

- **String Concatenation**:
  - **Line**: 
    ```python
    return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
    ```
  - **Issue**: String concatenation using `+` can be inefficient, especially if the number of sections is large.
  - **Why**: Each concatenation operation creates a new string, leading to multiple memory allocations and copies.

- **Redundant Checks**:
  - **Lines**: 
    ```python
    if self.imported_modules:
        ...
    if self.related_files:
        ...
    if self.graph_context:
        ...
    if self.trm_context:
        ...
    ```
  - **Issue**: These checks are redundant and can be optimized.
  - **Why**: Each check is performed separately, which can lead to unnecessary operations if multiple conditions are true.

### 3. Proposed Improvement
- **Dataclass Initialization**:
  - **Change**: Initialize `source_file` with a default value or use an optional type.
  - **Why**: This ensures that the attribute is always set and avoids runtime errors.
  - **Trade-offs**: Using an optional type (`Optional[str]`) allows for more flexibility but requires handling `None` values.

- **Efficient List Slicing**:
  - **Change**: Use a generator expression instead of list slicing.
  - **Why**: This avoids creating intermediate lists and is more memory-efficient.
  - **Trade-offs**: The code becomes slightly less readable, but the performance gain can be significant for large lists.

- **String Concatenation**:
  - **Change**: Use `str.join` to concatenate the sections.
  - **Why**: `str.join` is more efficient and avoids multiple memory allocations.
  - **Trade-offs**: The code becomes slightly more complex, but it is a best practice for string concatenation.

- **Optimized Checks**:
  - **Change**: Combine the checks into a single loop or use a dictionary to map attributes to their formatted strings.
  - **Why**: This reduces redundant operations and makes the code more maintainable.
  - **Trade-offs**: The code becomes slightly more complex, but it is more efficient and easier to extend.

### 4. Implementation Strategy
1. **Update Dataclass Initialization**:
   ```python
   from typing import Optional

   class ProactiveContext:
       """Context package assembled proactively."""

       source_file: Optional[str] = None
       related_files: list[str] = field(default_factory=list)
       imported_modules: list[str] = field(default_factory=list)
       graph_context: list[str] = field(default_factory=list)
       trm_context: str = ""
       confidence: float = 0.0

       def to_prompt_section(self) -> str:
           """Format as a prompt section for the LLM."""
           sections = []
   ```

2. **Optimize List Slicing**:
   ```python
   if self.imported_modules:
       sections.append(
           f"**Imports**: This file uses: {', '.join(islice(self.imported_modules, 10))}"
       )
   ```

3. **Efficient String Concatenation**:
   ```python
   return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
   ```

4. **Optimized Checks**:
   ```python
   def to_prompt_section(self) -> str:
       """Format as a prompt section for the LLM."""
       sections = []

       context_map = {
           "imported_modules": (self.imported_modules, "**Imports**: This file uses: {items}"),
           "related_files": (self.related_files, "**Related Files**: Often seen with: {items}"),
           "graph_context": (self.graph_context, "**Previous Insights**:\n{items}"),
           "trm_context": (self.trm_context, "**Recent Thoughts**:\n{items}")
       }

       for key, (items, template) in context_map.items():
           if items:
               formatted_items = ", ".join(islice(items, 10)) if isinstance(items, list) else items
               sections.append(template.format(items=formatted_items))

       return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
   ```

### 5. Testing Strategy
- **Unit Tests**:
  - Test the `ProactiveContext` class with various combinations of attributes to ensure it behaves as expected.
  - Test edge cases where some attributes are empty or not set.
  - Verify that the `to_prompt_section` method produces the correct formatted string.

- **Integration Tests**:
  - Integrate the `ProactiveContext` class with other components (e.g., LLM client) to ensure it works seamlessly in a real-world scenario.
  - Test performance with large lists of imported modules and related files.

By implementing these changes, the `ProactiveContext` class will be more robust, efficient, and maintainable. ## End of Analysis
``` ## Analysis

### 1. Current State Assessment
- **What is this code doing?**
  - The `ProactiveContext` class is designed to assemble a context package proactively for use in generating prompts for an LLM (Language Model). It includes various attributes such as `source_file`, `related_files`, `imported_modules`, `graph_context`, and `trm_context`. The `to_prompt_section` method formats these attributes into a structured string that can be used as part of a prompt.
- **What patterns/paradigms is it using?**
  - The class uses dataclass fields to initialize its attributes with default values. It also follows a builder pattern where the `to_prompt_section` method constructs a formatted string by conditionally appending relevant sections based on the presence of specific attributes.

### 2. Identified Issues
- **Dataclass Initialization**:
  - **Line**: `source_file: str`
  - **Issue**: The `source_file` attribute is not initialized with a default value, which can lead to issues if it is accessed before being set.
  - **Why**: This can cause `AttributeError` or other runtime errors if the attribute is accessed without being properly set.

- **List Slicing**:
  - **Lines**: 
    ```python
    sections.append(
        f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
    )
    ```
    ```python
    sections.append(
        f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
    )
    ```
  - **Issue**: The list slicing operations `[:10]` and `[:5]` can be inefficient if the lists are very large.
  - **Why**: Slicing a large list creates a new list, which can consume unnecessary memory and CPU cycles.

- **String Concatenation**:
  - **Line**: 
    ```python
    return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
    ```
  - **Issue**: String concatenation using `+` can be inefficient, especially if the number of sections is large.
  - **Why**: Each concatenation operation creates a new string, leading to multiple memory allocations and copies.

- **Redundant Checks**:
  - **Lines**: 
    ```python
    if self.imported_modules:
        ...
    if self.related_files:
        ...
    if self.graph_context:
        ...
    if self.trm_context:
        ...
    ```
  - **Issue**: These checks are redundant and can be optimized.
  - **Why**: Each check is performed separately, which can lead to unnecessary operations if multiple conditions are true.

### 3. Proposed Improvement
- **Dataclass Initialization**:
  - **Change**: Initialize `source_file` with a default value or use an optional type.
  - **Why**: This ensures that the attribute is always set and avoids runtime errors.
  - **Trade-offs**: Using an optional type (`Optional[str]`) allows for more flexibility but requires handling `None` values.

- **Efficient List Slicing**:
  - **Change**: Use a generator expression instead of list slicing.
  - **Why**: This avoids creating intermediate lists and is more memory-efficient.
  - **Trade-offs**: The code becomes slightly less readable, but the performance gain can be significant for large lists.

- **String Concatenation**:
  - **Change**: Use `str.join` to concatenate the sections.
  - **Why**: `str.join` is more efficient and avoids multiple memory allocations.
  - **Trade-offs**: The code becomes slightly more complex, but it is a best practice for string concatenation.

- **Optimized Checks**:
  - **Change**: Combine the checks into a single loop or use a dictionary to map attributes to their formatted strings.
  - **Why**: This reduces redundant operations and makes the code more maintainable.
  - **Trade-offs**: The code becomes slightly more complex, but it is more efficient and easier to extend.

### 4. Implementation Strategy
1. **Update Dataclass Initialization**:
   ```python
   from dataclasses import dataclass, field
   from typing import Optional, List

   @dataclass
   class ProactiveContext:
       """Context package assembled proactively."""

       source_file: Optional[str] = None
       related_files: List[str] = field(default_factory=list)
       imported_modules: List[str] = field(default_factory=list)
       graph_context: List[str] = field(default_factory=list)
       trm_context: str = ""
       confidence: float = 0.0

       def to_prompt_section(self) -> str:
           """Format as a prompt section for the LLM."""
           sections = []
   ```

2. **Optimize List Slicing**:
   ```python
   from itertools import islice

   class ProactiveContext:
       # ... (other methods and attributes)

       def to_prompt_section(self) -> str:
           """Format as a prompt section for the LLM."""
           sections = []

           if self.imported_modules:
               sections.append(
                   f"**Imports**: This file uses: {', '.join(islice(self.imported_modules, 10))}"
               )

           if self.related_files:
               sections.append(
                   f"**Related Files**: Often seen with: {', '.join(islice(self.related_files, 5))}"
               )

           if self.graph_context:
               sections.append(
                   "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in islice(self.graph_context, 3))
               )

           if self.trm_context:
               sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

           return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
   ```

3. **Efficient String Concatenation**:
   ```python
   class ProactiveContext:
       # ... (other methods and attributes)

       def to_prompt_section(self) -> str:
           """Format as a prompt section for the LLM."""
           sections = []

           if self.imported_modules:
               sections.append(
                   f"**Imports**: This file uses: {', '.join(islice(self.imported_modules, 10))}"
               )

           if self.related_files:
               sections.append(
                   f"**Related Files**: Often seen with: {', '.join(islice(self.related_files, 5))}"
               )

           if self.graph_context:
               sections.append(
                   "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in islice(self.graph_context, 3))
               )

           if self.trm_context:
               sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

           return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
   ```

4. **Optimized Checks**:
   ```python
   class ProactiveContext:
       # ... (other methods and attributes)

       def to_prompt_section(self) -> str:
           """Format as a prompt section for the LLM."""
           sections = []

           context_map = {
               "imported_modules": (self.imported_modules, "**Imports**: This file uses: {items}"),
               "related_files": (self.related_files, "**Related Files**: Often seen with: {items}"),
               "graph_context": (self.graph_context, "**Previous Insights**:\n{items}"),
               "trm_context": (self.trm_context, "**Recent Thoughts**:\n{items}")
           }

           for key, (items, template) in context_map.items():
               if items:
                   formatted_items = ", ".join(islice(items, 10)) if isinstance(items, list) else items
                   sections.append(template.format(items=formatted_items))

           return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
   ```

### 5. Testing Strategy
- **Unit Tests**:
  - Test the `ProactiveContext` class with various combinations of attributes to ensure it behaves as expected.
  - Test edge cases where some attributes are empty or not set.
  - Verify that the `to_prompt_section` method produces the correct formatted string.

  ```python
  import unittest

  class TestProactiveContext(unittest.TestCase):
      def test_to_prompt_section(self):
          context = ProactiveContext(
              source_file="main.py",
              related_files=["models.py", "config.py"],
              imported_modules=["os", "sys", "json"],
              graph_context=["Previous Insight 1", "Previous Insight 2", "Previous Insight 3"],
              trm_context="Recent Thoughts: This is a test."
          )
          expected_output = (
              "## Proactive Context (anticipated relevant info)\n\n"
              "**Imports**: This file uses: os, sys, json\n\n"
              "**Related Files**: Often seen with: models.py, config.py\n\n"
              "**Previous Insights**:\n- Previous Insight 1\n- Previous Insight 2\n- Previous Insight 3\n\n"
              "**Recent Thoughts**:\nRecent Thoughts: This is a test."
          )
          self.assertEqual(context.to_prompt_section(), expected_output)

      def test_empty_attributes(self):
          context = ProactiveContext()
          self.assertEqual(context.to_prompt_section(), "")

      def test_partial_attributes(self):
          context = ProactiveContext(
              imported_modules=["os", "sys"],
              trm_context="Recent Thoughts: This is a test."
          )
          expected_output = (
              "## Proactive Context (anticipated relevant info)\n\n"
              "**Imports**: This file uses: os, sys\n\n"
              "**Recent Thoughts**:\nRecent Thoughts: This is a test."
          )
          self.assertEqual(context.to_prompt_section(), expected_output)

  if __name__ == '__main__':
      unittest.main()
  ```

- **Integration Tests**:
  - Integrate the `ProactiveContext` class with other components (e.g., LLM client) to ensure it works seamlessly in a real-world scenario.
  - Test performance with large lists of imported modules and related files.

By implementing these changes, the `ProactiveContext` class will be more robust, efficient, and maintainable. ## End of Analysis
```

## Suggested Implementation

```python

from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
            )

        if self.related_files:
            sections.append(
                f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
            )

        if self.graph_context:
            sections.append(
                "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in self.graph_context[:3])
            )

        if self.trm_context:
            sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

        if not sections:
            return ""

        return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
```
```python
from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
            )

        if self.related_files:
            sections.append(
                f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
            )

        if self.graph_context:
            sections.append(
                "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in self.graph_context[:3])
            )

        if self.trm_context:
            sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

        if not sections:
            return ""

        return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
```
```python
from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
            )

        if self.related_files:
            sections.append(
                f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
            )

        if self.graph_context:
            sections.append(
                "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in self.graph_context[:3])
            )

        if self.trm_context:
            sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

        if not sections:
            return ""

        return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
```
```python
from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
            )

        if self.related_files:
            sections.append(
                f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
            )

        if self.graph_context:
            sections.append(
                "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in self.graph_context[:3])
            )

        if self.trm_context:
            sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

        if not sections:
            return ""

        return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
```
```python
from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
            )

        if self.related_files:
            sections.append(
                f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
            )

        if self.graph_context:
            sections.append(
                "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in self.graph_context[:3])
            )

        if self.trm_context:
            sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

        if not sections:
            return ""

        return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
```
```python
from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
            )

        if self.related_files:
            sections.append(
                f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
            )

        if self.graph_context:
            sections.append(
                "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in self.graph_context[:3])
            )

        if self.trm_context:
            sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

        if not sections:
            return ""

        return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
```
```python
from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
            )

        if self.related_files:
            sections.append(
                f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
            )

        if self.graph_context:
            sections.append(
                "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in self.graph_context[:3])
            )

        if self.trm_context:
            sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

        if not sections:
            return ""

        return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
```
```python
from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
            )

        if self.related_files:
            sections.append(
                f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
            )

        if self.graph_context:
            sections.append(
                "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in self.graph_context[:3])
            )

        if self.trm_context:
            sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

        if not sections:
            return ""

        return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
```
```python
from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
            )

        if self.related_files:
            sections.append(
                f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
            )

        if self.graph_context:
            sections.append(
                "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in self.graph_context[:3])
            )

        if self.trm_context:
            sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

        if not sections:
            return ""

        return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
```
```python
from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {', '.join(self.imported_modules[:10])}"
            )

        if self.related_files:
            sections.append(
                f"**Related Files**: Often seen with: {', '.join(self.related_files[:5])}"
            )

        if self.graph_context:
            sections.append(
                "**Previous Insights**:\n" + "\n".join(f"- {c}" for c in self.graph_context[:3])
            )

        if self.trm_context:
            sections.append(f"**Recent Thoughts**:\n{self.trm_context}")

        if not sections:
            return ""

        return "## Proactive Context (anticipated relevant info)\n\n" + "\n\n".join(sections)
```
```python
from dataclasses import dataclass, field

@dataclass
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str = ""
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        sections = []

        if self.imported_modules:
            sections.append(
                f"**Imports**: This file uses: {',
```

---

## Seed Context

```
# class: ProactiveContext
# Context package assembled proactively.
class ProactiveContext:
    """Context package assembled proactively."""

    source_file: str
    related_files: list[str] = field(default_factory=list)
    imported_modules: list[str] = field(default_factory=list)
    graph_context: list[str] = field(default_factory=list)
    trm_context: str = ""
    confidence: float = 0.0

    def to_prompt_section(self) -> str:
        """Format as a prompt section for the LLM."""
        s
```
